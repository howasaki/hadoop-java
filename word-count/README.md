# Hadoop WordCount Project

Este proyecto implementa un ejemplo cl√°sico de **MapReduce** para contar la frecuencia de palabras en archivos de texto utilizando el framework Apache Hadoop.

## üìã Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado y configurado lo siguiente en tu entorno:

- **Java JDK 8**: Necesario para compilar y ejecutar aplicaciones Hadoop.
- **Apache Maven**: Para la gesti√≥n de dependencias y construcci√≥n del proyecto.
- **Apache Hadoop 3.4.x**: El cl√∫ster o instalaci√≥n local de Hadoop debe estar en ejecuci√≥n.

## üõ†Ô∏è Dependencias

El proyecto utiliza las siguientes dependencias principales (definidas en el `pom.xml`):

- `hadoop-common` (3.4.2)
- `hadoop-client` (3.4.2)
- `hadoop-mapreduce-client-core` (3.4.2)

## üì¶ Compilaci√≥n

Para compilar el proyecto y generar el archivo JAR ejecutable, sit√∫ate en la ra√≠z del proyecto y ejecuta:

```bash
mvn clean package
```

Una vez finalizado, se generar√° el archivo `word-count-1.0.jar` dentro del directorio `target/`.

## üöÄ Ejecuci√≥n en Hadoop

Sigue estos pasos para ejecutar el trabajo de MapReduce en tu cl√∫ster Hadoop:

### 1. Preparar los datos de entrada
Crea un archivo de texto de prueba (ej. `input.txt`) con alg√∫n contenido y s√∫belo al sistema de archivos distribuido (HDFS).

```bash
# Crear un archivo de prueba local
echo "hola mundo hadoop hola java mapreduce" > input.txt

# Crear directorio en HDFS (opcional)
hdfs dfs -mkdir -p /user/hadoop/wordcount/input

# Subir el archivo a HDFS
hdfs dfs -put input.txt /user/hadoop/wordcount/input/
```

### 2. Ejecutar el trabajo (Job)
Utiliza el comando `hadoop jar` para enviar el trabajo al cl√∫ster. Aseg√∫rate de especificar la ruta de entrada y la de salida (la ruta de salida no debe existir previamente).

```bash
hadoop jar target/word-count-1.0.jar /user/hadoop/wordcount/input /user/hadoop/wordcount/output
```

*Nota: La clase principal est√° configurada en el manifiesto del JAR (`com.maestria.hadoop.WordCount`), por lo que no es estrictamente necesario especificarla en el comando, pero si lo fuera, el comando ser√≠a:*
`hadoop jar target/word-count-1.0.jar com.maestria.hadoop.WordCount /user/hadoop/wordcount/input /user/hadoop/wordcount/output`

### 3. Verificar los resultados
Una vez que el trabajo haya finalizado correctamente, puedes verificar la salida generada en HDFS.

```bash
# Listar los archivos de salida
hdfs dfs -ls /user/hadoop/wordcount/output

# Ver el contenido del resultado (normalmente part-r-00000)
hdfs dfs -cat /user/hadoop/wordcount/output/part-r-00000
```

### Salida esperada
Para el ejemplo anterior, la salida deber√≠a ser similar a:
```text
hadoop	1
hola	2
java	1
mapreduce	1
mundo	1
```

## üßπ Limpieza
Para volver a ejecutar el trabajo, debes eliminar el directorio de salida en HDFS, ya que Hadoop no sobrescribe directorios existentes por seguridad.

```bash
hdfs dfs -rm -r /user/hadoop/wordcount/output